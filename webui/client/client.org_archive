#    -*- mode: org -*-


Archived entries from file /home/zz/apisnoop/webui/client/client.org


* index mounted to dom.
  :PROPERTIES:
  :ARCHIVE_TIME: 2018-11-07 Wed 04:05
  :ARCHIVE_FILE: ~/apisnoop/webui/client/client.org
  :ARCHIVE_OLPATH: The Code/index.js
  :ARCHIVE_CATEGORY: client
  :END:
Here we define the wrapped up chunk of code that will be mounted to the 'root' id in our index.html page, and flower into the full app
#+NAME: main index.js
#+BEGIN_SRC js
#+END_SRC

Archived entries from file /home/zz/apisnoop/webui/client/client.org


* Requirements
  :PROPERTIES:
  :ARCHIVE_TIME: 2018-11-07 Wed 04:05
  :ARCHIVE_FILE: ~/apisnoop/webui/client/client.org
  :ARCHIVE_OLPATH: The Code/index.js
  :ARCHIVE_CATEGORY: client
  :END:
  #+NAME: Requirements
  #+BEGIN_SRC js
  #+END_SRC

* Working with d3
  :PROPERTIES:
  :ARCHIVE_TIME: 2018-12-05 Wed 14:22
  :ARCHIVE_FILE: ~/ii/apisnoop/webui/client/client.org
  :ARCHIVE_OLPATH: Footnotes
  :ARCHIVE_CATEGORY: client
  :END:
** Introduction
   d3 is the data visualization library that was used to make our original sunburst.  The way it works is to mount itself to the dom, and then appends new elements to the dom based on the data it was given. If that data changes, it transforms the elements as needed.

   The way react works is it attaches itself to the dom, then creates a //shadow dom// that it is continually listening to, adding and removing elements in this dom as needed based on the data(the state) it was given.

   In other words, they work in largely the same way, and both wanna attach themselves to the dom and manipulate it.  This...isn't good.  We want to have /1/ thing making shadow doms and calls on the website, and so it is a bit tricky to get react and d3 working together.

The upside is that a number of people have tackled this challenge and created different react/d3 libraries for how the two can work together.  The downside is that I'm not sure yet which is the best to do.

Put simply, it is not easy to take our existing sunburst code and just paste it into our new app.  We are going to need to transform it in some way based on the guidance of the library we are using.

So the question is why we are putting ourselves into this trouble?
** WHY WE ARE PUTTING OURSELVES INTO THIS TROUBLE
    My assumption with all of this is that when people hear 'apisnoop', they are thinking of the site in which you can see the data visualziations.  And so the webapp is important for the project and will be expanded.  React would be great for this in the long run.

Similarly, I am expecting that we are going to have more types of visualizations than just the sunburst--and that even the sunburst may change.  So we are going to want to have an understanding for a language in which we can make a //bunch// of visualizations. d3 is great for this.

If we do it right, we can have reusable components too that other teams could use for their own k8s projects, and that we could use ourselves.  For example--displaying two sunburst charts side by side would be much easier in react/d3 then what i ws trying to do before (appending both to the same id on a standard html document.)  This requires that I move through some d3 tutorials though.

At the end of this, though, we will have a backend server that is easy to setup and can ping different url's (github repos or testgrid artifacts) and grab their data.  Then, we can manipulate that data in whatever way we want but also pass it along to our frontend.  This front-end can then have different options and tags setto really dive in and explore.

If this is the purpose of apisnoop then let's do it.  If it's too much overkill though, then I can try a simpler solution.
** Possible Process to get going
*** Setup a simple d3 visualization to understand the process
*** pipe data into this simple visualization through our redux state.
*** Pore over the original code again (the original blog post) to see how to best convert it
*** Change the sunburst's origin point from a CSV file to JSON
*** Change the sunbursts origin point from JSON to our redux store.
** Second Process
*** Setup different pages for different d3-react libraries that already have ubilt components.
*** explore piping our data into the one we like.
*** Use testgrid conformance data and make simple visualizations to it.
    We are wanting to keep the data retrieval tied into the visualizing, so we dont' end up with a pretty graph that can't be used for what we have.  So we can grab the testgrid stuff now and see what we can do with it.


*** Use that going forward.
** Possible Libraries to use
*** Victory
    https://formidable.com/open-source/victory/
*** Britecharts react
    https://eventbrite.github.io/britecharts-react/
*** Recharts
    http://recharts.org/en-US/

* Aaron Feedback
  :PROPERTIES:
  :ARCHIVE_TIME: 2018-12-05 Wed 14:22
  :ARCHIVE_FILE: ~/ii/apisnoop/webui/client/client.org
  :ARCHIVE_OLPATH: Footnotes
  :ARCHIVE_CATEGORY: client
  :END:
- useful troubleshooting tool:
  - adding test names to user agents to verify a test was testing what we thought it was.
  - filter audit logs by user-agent and then see 'when this test case is run, here are the endpoints it accesses chronologically".
    - This is separate from number of times hit.  that is useful in aggregate, this is something different.
  - pulling in an audit log of timestamp/verb/uri
- Feature of pointing to the specific line in the source for each test, to pull its definition, would be a good //Next// step.
  - This is something we can do with whakapapa, but it's not something we have now.
- Discovery front: Filtering more endpoints from APIsnoop's definition of coverage.
  - If beta endpoints always get hit because an api server is doing discovery, then that's cool but nothing we can ever prevent conformance tests from doing and we shouldn't care about it from a test coverage perspective.
  - How do we signify that this is the kinda hit that's happening for an endpoint?
  - We have a good start with filtering to just e2e, but even our e2etests are hitting those endpoints.  There are some endpoints where, logically they don't need to get tested or anything like that.
  - Get to a point whwere we can manually specify, or have a blacklist of apiendpoints that we aren't factoring into our coverage viz.
  - One way to do this is to filter out the endpoints that are hit by nearly all of the tests.  This is a good indicator that the endpoint is for initialization or something like that, and not actually a part of this test's function.
- Unique Endpoints hit by a test: this is something that isn't covered by our sunburst or katherine's viz.  Pick a test, and then see the endpoints that are //only// hit by this test.
  - which endpoints hit are unique, versus which ones are common across all test cases.  This would let us know which test cases are doing good stuff and which endpoints are essentially meaningless.
  - you could have a center endpoint change to the perspective of that test, and then that test would only show the endpoints that it hits.....but that may not be that useful.  We dont' wanna see All the endpoints, we wanna see which ones are //special// for this test.
  - Hierarchy vizes aren't that useful.
  - I just wanna find a way to slice and dice data with raw queries and see where that leads us...and take some of the more useful queries and generate reports from that.  This sounds like a new approach for apisnoop.

Question from this, then: Who is apisnoop's audience?  Is it Aaron,and people like aaron?  is it a kubernetes end user?  If it's aaraon, he is saying he knows how to write certain queries, but he would rather have this  already done and then he can do further exploration.
'For an endpoint that's only hit three times, what are the tests that are hitting this endpoint.  And then we could follow up with what the tests are doing from an api perspective.  'Okay, now let me see the full api stream from this test."
 - auotmate this, or provide shiny reports for this.  This isn't the end user coming up with the interesting things, this is us coming up with interesting things that we are letting the end user come to their own conclusions on.
 - We eventually want to show api coverage going up over time across different builds. o
 - We might be able to format things in such a way to have a test dashboard that shows individual api endpoints and #'s: how many times they been hit, something like that.
 - Is code coverage a different thing?  when talking about it being a command line tool that generates reports from it...or is that just what the group is trying to do.  the benefit of the command line tool is that you can automate it running for every build. We could then just have a page that displays these reports even maybe.
 - We want to share shinies at kubeconf china.
 - Get visualization up to good place that replaces existing visualization.
 - Showing all the api accesses per user-agent or test as a different Dashboard to have.
 - Take care of you for whatever demos you need for apisnoop.
 - It would be worth it to show we're providing value to cncf as a whole, but right now it's good to just be able to have Aaron say that the work we're doing makes it easier for conformance to do the things they want to do.
 - Let's not work on things that don't end up providing value, over-delivering when he really just wants somethings maller and specific.  He's happy to have some reports that don't need to be that shiny, but maybe a little bit interactive.  and these reports would be:
   - If I click on a user agent, I can see the in-order access of all the api endpoints.
   - To get some kind of report that shows me what kind of endpoints don't matter (every test hits them) and which ones are interesting (cos only a few endpoints hit them) and what are those tests?
     - this may lead to a point where we try to make a whitelist of endpoints in our coverage, but let's not cross that bridge yet.
   - For wednesday deadline...this isn't a hard deadline, we can touch base on Tuesday/Monday and see where we at.

* Pairing With Mikey
  :PROPERTIES:
  :ARCHIVE_TIME: 2018-12-05 Wed 14:22
  :ARCHIVE_FILE: ~/ii/apisnoop/webui/client/client.org
  :ARCHIVE_OLPATH: Footnotes
  :ARCHIVE_CATEGORY: client
  :END:
** Background
   I went through a pairing Session with [[https://dinosaur.is][Mikey]], to help with the overall architecture and code logic of the webui
